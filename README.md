# ğŸ­ Twitter Sentiment Analysis: A Multi-Model Comparative Study

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://tensorflow.org/)
[![Transformers](https://img.shields.io/badge/ğŸ¤—%20Transformers-4.x-yellow.svg)](https://huggingface.co/transformers/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> *A comprehensive sentiment analysis pipeline comparing classical machine learning, deep learning, and transformer-based approaches on Twitter data*

## ğŸ“‹ Overview

This project implements and evaluates multiple sentiment classification methodologies on the Sentiment140 dataset, providing insights into the performance trade-offs between traditional ML algorithms, LSTM networks, and state-of-the-art transformer models. The analysis demonstrates practical expertise in end-to-end NLP pipeline development whilst offering actionable insights for production deployment.

### ğŸ¯ Key Features

- **Multi-Model Architecture**: Implementation of 6 different models ranging from classical ML to transformers
- **Comprehensive Preprocessing**: Advanced text cleaning with regex patterns, lemmatisation, and stopword removal
- **Performance Benchmarking**: Detailed accuracy and F1-score comparisons across all models
- **Visualisation Suite**: Word clouds, distribution plots, and performance comparison charts
- **Production-Ready Code**: Modular, well-documented implementation suitable for scaling

## ğŸ—ï¸ Architecture

```
ğŸ“¦ Sentiment Analysis Pipeline
â”œâ”€â”€ ğŸ“Š Data Processing
â”‚   â”œâ”€â”€ Text cleaning & normalisation
â”‚   â”œâ”€â”€ Tokenisation & lemmatisation
â”‚   â””â”€â”€ TF-IDF vectorisation
â”œâ”€â”€ ğŸ¤– Model Implementation
â”‚   â”œâ”€â”€ Classical ML (Logistic Regression, Naive Bayes, SVM)
â”‚   â”œâ”€â”€ Deep Learning (LSTM with embeddings)
â”‚   â””â”€â”€ Transformers (DistilBERT)
â””â”€â”€ ğŸ“ˆ Evaluation & Visualisation
    â”œâ”€â”€ Performance metrics calculation
    â”œâ”€â”€ Confusion matrices
    â””â”€â”€ Comparative analysis plots
```

## ğŸš€ Quick Start

### Prerequisites

```bash
python >= 3.8
tensorflow >= 2.8
transformers >= 4.0
scikit-learn >= 1.0
nltk >= 3.7
```

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/twitter-sentiment-analysis.git
cd twitter-sentiment-analysis

# Install dependencies
pip install -r requirements.txt

# Download NLTK resources
python -c "import nltk; nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('omw-1.4')"
```

### Usage

```python
# Run the complete analysis pipeline
python sentiment_analysis.py

# Or execute individual components
from src.models import SentimentClassifier
from src.preprocessing import TextPreprocessor

# Initialize and train models
classifier = SentimentClassifier()
results = classifier.train_all_models(data_path="sentiment140.csv")
```

## ğŸ“Š Results & Performance

| Model | Accuracy | F1-Score | Training Time | Inference Speed |
|-------|----------|----------|---------------|-----------------|
| **Logistic Regression** | 0.8234 | 0.8198 | ~2 mins |  Fast |
| **Naive Bayes** | 0.8156 | 0.8142 | ~1 min |  Fast |
| **SVM (Linear)** | 0.8289 | 0.8267 | ~3 mins |  Fast |
| **LSTM** | 0.8456 | 0.8445 | ~15 mins |  Medium |
| **DistilBERT** | **0.8734** | **0.8721** | ~45 mins |  Slow |

### ğŸ” Key Insights

- **Best Overall Performance**: DistilBERT achieved highest accuracy (87.34%) but with significant computational overhead
- **Best Efficiency**: SVM provides excellent accuracy to speed ratio for resource constrained environments  
- **Sweet Spot**: LSTM offers good balance between performance and computational requirements
- **Classical ML Resilience**: Traditional algorithms remain competitive, especially considering deployment constraints

## ğŸ› ï¸ Technical Implementation

### Data Preprocessing Pipeline
```python
def clean_tweet(text):
    """Advanced text preprocessing with regex patterns"""
    text = text.lower()
    text = re.sub(r"http\S+|www\S+", "", text)    # Remove URLs
    text = re.sub(r"@\w+", "", text)              # Remove mentions  
    text = re.sub(r"#", "", text)                 # Remove hashtags
    text = re.sub(r"[^a-zA-Z\s]", "", text)       # Remove punctuation
    # Lemmatisation and stopword removal
    tokens = [lemmatizer.lemmatize(word) for word in text.split() 
              if word not in stop_words]
    return " ".join(tokens)
```

### Model Architectures

**LSTM Network**:
- Embedding layer (128 dimensions)
- LSTM layer (128 units, 20% dropout)
- Dense output layer (3 classes, softmax)

**DistilBERT Fine-tuning**:
- Pre-trained DistilBERT base model
- Sequence classification head
- Learning rate: 5e-5, 2 epochs

## ğŸ“ˆ Visualisations

The project generates comprehensive visualisations including:

- **Sentiment Distribution**: Dataset balance analysis
- **Word Clouds**: Most frequent terms per sentiment class
- **Performance Comparison**: Bar charts comparing model metrics
- **Confusion Matrices**: Detailed classification performance breakdown

## ğŸ¯ Business Applications

This sentiment analysis framework supports various commercial applications:

- **Brand Monitoring**: Real time social media sentiment tracking
- **Customer Feedback Analysis**: Automated review classification
- **Market Research**: Public opinion analysis for product launches  
- **Crisis Management**: Early detection of negative sentiment trends

## ğŸ”¬ Technical Deep Dive

### Feature Engineering
- **TF-IDF Vectorisation**: 5,000 feature vocabulary with sublinear scaling
- **Sequence Processing**: 50-token padding for LSTM input consistency
- **Transformer Tokenisation**: DistilBERT tokeniser with 64-token truncation

### Model Selection Rationale
- **Classical ML**: Baseline performance with minimal computational overhead
- **LSTM**: Sequential processing for contextual understanding
- **DistilBERT**: State of the art language model with attention mechanisms

## ğŸš€ Future Enhancements

- [ ] **Multi-language Support**: Extend to non English tweets
- [ ] **Real-time Pipeline**: Implement streaming data processing
- [ ] **Model Ensemble**: Combine predictions from multiple models
- [ ] **Advanced Metrics**: Add precision/recall curves and ROC analysis
- [ ] **Hyperparameter Optimisation**: Grid search for optimal configurations
- [ ] **Docker Deployment**: Containerised solution for cloud deployment

## ğŸ“ Project Structure

```
twitter-sentiment-analysis/
â”œâ”€â”€ ğŸ““ notebooks/
â”‚   â””â”€â”€ sentiment_analysis.ipynb
â”œâ”€â”€ ğŸ“œ src/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â””â”€â”€ visualisation.py
â”œâ”€â”€ ğŸ“Š data/
â”‚   â””â”€â”€ sentiment140.csv
â”œâ”€â”€ ğŸ“¸ results/
â”‚   â”œâ”€â”€ performance_plots/
â”‚   â””â”€â”€ model_metrics.json
â”œâ”€â”€ ğŸ“‹ requirements.txt
â”œâ”€â”€ ğŸ³ Dockerfile
â””â”€â”€ ğŸ“– README.md
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit pull requests or open issues for bugs and feature requests.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

**Osman Hassan Abdi**
- ğŸ”— LinkedIn:https://www.linkedin.com/in/osman-abdi-5a6b78b6/
- ğŸ™ GitHub:https://github.com/oabdi444/ 
